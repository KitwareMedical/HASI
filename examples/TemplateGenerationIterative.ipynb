{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Template Generation\n",
    "\n",
    "This notebook exemplifies one way in which a template mesh atlas can be generated from a collection of segmented binary images. Each binary image of a mouse femur is downsampled to reduce pixel density prior to applying marching cubes to generate a mesh from the binary image. One arbitrary mesh is selected as the template and then registered to and resampled from each original mesh to get a full set of meshes with correspondence points. The meshes are then groupwise registered via procrustes alignment and the mean mesh is taken as the new template. This process is repeated for a fixed number of iterations to get a template mesh atlas that represents the average case of all meshes.\n",
    "\n",
    "This pipeline uses the [ITKShape](https://github.com/slicersalt/ITKShape) module for shape analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import itk\n",
    "import sys\n",
    "from itkwidgets import view, checkerboard\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.hasi.hasi.pointsetentropyregistrar import PointSetEntropyRegistrar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read images\n",
    "\n",
    "Input images represent the results of automatic binary segmentations of mouse femur data. Each image contains only the femur object and potentially represents a different region in space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = 'Input/femurs/'\n",
    "DENSE_MESH_OUTPUT_FOLDER = 'Output/femurs/'\n",
    "TEMPLATE_OUTPUT_FOLDER = 'Output/templates/'\n",
    "MEAN_OUTPUT_FOLDER = 'Output/mean/'\n",
    "\n",
    "for folder in [IMAGE_FOLDER, DENSE_MESH_OUTPUT_FOLDER, TEMPLATE_OUTPUT_FOLDER, MEAN_OUTPUT_FOLDER]:\n",
    "    os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Input/femurs\\\\901-R-femur-label.nrrd', 'Input/femurs\\\\902-R-femur-label.nrrd', 'Input/femurs\\\\906-R-femur-label.nrrd', 'Input/femurs\\\\907-R-femur-label.nrrd', 'Input/femurs\\\\908-R-femur-label.nrrd', 'Input/femurs\\\\915-R-femur-label.nrrd', 'Input/femurs\\\\916-R-femur-label.nrrd', 'Input/femurs\\\\917-R-femur-label.nrrd', 'Input/femurs\\\\918-R-femur-label.nrrd', 'Input/femurs\\\\F9-3wk-01-R-femur-label.nrrd', 'Input/femurs\\\\F9-3wk-02-R-femur-label.nrrd', 'Input/femurs\\\\F9-3wk-03-R-femur-label.nrrd', 'Input/femurs\\\\F9-8wk-01-R-femur-label.nrrd', 'Input/femurs\\\\F9-8wk-02-R-femur-label.nrrd']\n"
     ]
    }
   ],
   "source": [
    "# Get healthy femur segmentation binary images at \n",
    "# https://data.kitware.com/#collection/5dcc6691e3566bda4b802172/folder/5e0b8d6baf2e2eed35c326f7\n",
    "\n",
    "input_paths = glob.glob(IMAGE_FOLDER + '*-R-*')\n",
    "assert(len(input_paths) == 14)\n",
    "\n",
    "print(input_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESH_FILENAMES = [os.path.basename(file).replace('.nrrd','.obj') for file in input_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list()\n",
    "for path in input_paths:\n",
    "    images.append(itk.imread(path, itk.UC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paste images into same space\n",
    "\n",
    "Here we standardize physical space across the femur images. This is primarily intended to assist in viewing convenience with `itkwidgets` which expects a standard viewing region, but could also be helpful to standardize output from subsequent image downsampling and mesh conversion operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify image spacing is equivalent\n",
    "TOLERANCE = 0.0000001\n",
    "assert(all([itk.spacing(images[i])[j] - itk.spacing(images[i+1])[j] < TOLERANCE\n",
    "            for j in range(0,images[0].GetImageDimension())\n",
    "            for i in range(0,len(images) - 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itkSize3 ([1279, 954, 1039])\n"
     ]
    }
   ],
   "source": [
    "# Get largest range containing images\n",
    "max_size = itk.size(images[0])\n",
    "for image in images:\n",
    "    for i in range(0,len(max_size)):\n",
    "        max_size[i] = max(max_size[i], itk.size(image)[i])\n",
    "print(max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make image of common size\n",
    "def paste_common_size(orig_image, size, spacing):\n",
    "    dimension = orig_image.GetImageDimension()\n",
    "    region = itk.ImageRegion[dimension]()\n",
    "    region.SetSize(size)\n",
    "    region.SetIndex([0] * dimension)\n",
    "\n",
    "    new_image = type(orig_image).New()\n",
    "    new_image.SetRegions(region)\n",
    "    new_image.SetSpacing(spacing)\n",
    "    new_image.Allocate()\n",
    "    \n",
    "    paste_filter = itk.PasteImageFilter[type(orig_image)].New()\n",
    "    paste_filter.SetSourceImage(orig_image)\n",
    "    paste_filter.SetSourceRegion(orig_image.GetLargestPossibleRegion())\n",
    "    paste_filter.SetDestinationImage(new_image)\n",
    "    paste_filter.SetDestinationIndex([0,0,0])\n",
    "    paste_filter.Update()\n",
    "    \n",
    "    return paste_filter.GetOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make images common size\n",
    "for i in range(0, len(images)):\n",
    "    images[i] = paste_common_size(images[i], max_size, images[0].GetSpacing())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c24adb830a56485292265239f102b44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[], gradient_opacity=0.22, point_sets=[], rendered_image=<itk.itkImagePython.itkImageUC3; pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View a 3D image with itkwidgets\n",
    "view(images[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample images\n",
    "\n",
    "The marching cubes algorithm returns a mesh with vertex density related to the pixel density of the original image. Here we downsample each image twice, once to get a \"dense\" image retaining most information density and a second time to get a \"sparse\" image more easily applied to get correspondence points.\n",
    "\n",
    "Meshes generated later from the dense images have approximately 600,000 vertices each while meshes generated from the sparse images have approximately 4,000 vertices. We will use the dense meshes to sample feature information and iteratively refine a the atlas to generalize the shape population. We can select a single sparse mesh to act as the initial atlas or carry out iterative refinement on multiple sparse meshes and compare to determine which result \"best\" reflects the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPARSE_DOWNSAMPLE_RATIO = 14\n",
    "DENSE_DOWNSAMPLE_RATIO = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_images(image_list, ratio) -> list:\n",
    "    downsamples = list()\n",
    "    for image in image_list:\n",
    "        output_spacing = [spacing * ratio for spacing in itk.spacing(image)]\n",
    "        output_size = [int(size / ratio) for size in itk.size(image)]\n",
    "\n",
    "        downsample = itk.resample_image_filter(Input=image,\n",
    "                                               Size=output_size,\n",
    "                                               OutputOrigin=itk.origin(image),\n",
    "                                               OutputSpacing=output_spacing,)\n",
    "        downsamples.append(downsample)\n",
    "    return downsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itkSize3 ([639, 477, 519])\n",
      "itkSize3 ([91, 68, 74])\n"
     ]
    }
   ],
   "source": [
    "sparse_downsampled_images = downsample_images(images,SPARSE_DOWNSAMPLE_RATIO)\n",
    "dense_downsampled_images = downsample_images(images,DENSE_DOWNSAMPLE_RATIO)\n",
    "\n",
    "print(itk.size(dense_downsampled_images[0]))\n",
    "print(itk.size(sparse_downsampled_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3023646685ae428b92a13e8378fd0f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Viewer(geometries=[], gradient_opacity=0.22, point_sets=[], rendered_image=<itk.itkImagePython.itkImageUC3; pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view(dense_downsampled_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Meshes\n",
    "The `itk.BinaryMask3DMeshSource` class makes use of the Marching Cubes algorithm to generate a mesh from a given object. Each binary image here uses the value '1' to indicate the femur is present at a pixel and '0' to indicate the femur is not present. Marching Cubes rapidly fills the femur space and generates surfaces at pixel region boundaries.\n",
    "\n",
    "Note that it may be useful to visually examine intermediate results. In the case where a mesh is not well aligned with others it is useful to correct the transformation in an external mesh editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here each pixel interior to the femur has value \"1\" and exterior has value \"0\".\n",
    "# This may change for a different segmentation image.\n",
    "FEMUR_OBJECT_PIXEL_VALUE = 1\n",
    "\n",
    "Dimension = itk.template(sparse_downsampled_images[0])[1][1]\n",
    "MeshType = itk.Mesh[itk.F,Dimension]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_meshes(images:list, mesh_type=itk.Mesh[itk.F,3]) -> list:\n",
    "    meshes = list()\n",
    "    for image in images:\n",
    "        mesh = itk.binary_mask3_d_mesh_source(image, \n",
    "                               object_value=1, \n",
    "                               ttype=[type(images[0]),mesh_type])\n",
    "        meshes.append(mesh)\n",
    "    return meshes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average dense mesh points: 215290.5\n"
     ]
    }
   ],
   "source": [
    "dense_meshes = generate_meshes(dense_downsampled_images)\n",
    "\n",
    "# Expect ~200K vertices\n",
    "print('Average dense mesh points: ' +\n",
    "      str(sum([mesh.GetNumberOfPoints() for mesh in dense_meshes]) / len(dense_meshes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sparse mesh points: 4373.357142857143\n"
     ]
    }
   ],
   "source": [
    "sparse_meshes = generate_meshes(sparse_downsampled_images)\n",
    "\n",
    "# Expect ~5K vertices\n",
    "print('Average sparse mesh points: ' +\n",
    "      str(sum([mesh.GetNumberOfPoints() for mesh in sparse_meshes]) / len(sparse_meshes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write out each mesh to disk\n",
    "for i in range(0,len(dense_meshes)):\n",
    "    itk.meshwrite(dense_meshes[i], f'{DENSE_MESH_OUTPUT_FOLDER}{MESH_FILENAMES[i]}')\n",
    "\n",
    "for i in range(0,len(sparse_meshes)):\n",
    "    itk.meshwrite(sparse_meshes[i], f'{TEMPLATE_OUTPUT_FOLDER}{MESH_FILENAMES[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize with itkwidgets\n",
    "#view(geometries=sparse_meshes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Iterative Registration\n",
    "It is desired to find correspondence points between the template and each sample mesh. In order to get correspondence, two steps are employed:\n",
    "- First, a copy of the template mesh is registered to the target sample;\n",
    "- Second, each mesh point is repositioned at its nearest neighbor on the target sample.\n",
    "\n",
    "The result of this process is a full collection of meshes having the same number of points and correspondence between each point such that it represents the same approximate feature on each femur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def register_template_to_sample(template_mesh, \n",
    "                                sample_mesh,\n",
    "                                learning_rate=1.0,\n",
    "                                max_iterations=500):\n",
    "    \n",
    "    registrar = PointSetEntropyRegistrar()\n",
    "    metric = itk.EuclideanDistancePointSetToPointSetMetricv4[itk.PointSet[itk.F,3]].New()\n",
    "    transform = itk.Euler3DTransform[itk.D].New()\n",
    "    \n",
    "    # Make a deep copy of the template point set to register to the target\n",
    "    template_copy = itk.Mesh[itk.F,3].New()\n",
    "    for i in range(0, template_mesh.GetNumberOfPoints()):\n",
    "        template_copy.SetPoint(i, template_mesh.GetPoint(i))\n",
    "    template_copy.SetCells(template_mesh.GetCells())\n",
    "    \n",
    "    # Run registration and transform points to target\n",
    "    (transform, deformed_mesh) = registrar.register(template_mesh=template_copy,\n",
    "                                                    target_mesh=sample_mesh,\n",
    "                                                    metric=metric,\n",
    "                                                    transform=transform,\n",
    "                                                    learning_rate=learning_rate,\n",
    "                                                    max_iterations=max_iterations,\n",
    "                                                    resample_from_target=True,\n",
    "                                                    verbose=False)\n",
    "    return deformed_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Procrustes Alignment Parameters\n",
    "Once template meshes have been aligned to represent each input mesh with correspondence we can run Procrustes alignment and get out a mean mesh as the new template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_procrustes(deformed_meshes, \n",
    "                     template_index, \n",
    "                     verbose=False,\n",
    "                     convergence=0.08):\n",
    "    \n",
    "    procrustes_filter = itk.MeshProcrustesAlignFilter[type(deformed_meshes[0]), type(deformed_meshes[0])].New()\n",
    "    \n",
    "    procrustes_filter.SetUseInitialAverageOff()\n",
    "    procrustes_filter.SetUseNormalizationOff()\n",
    "    procrustes_filter.SetUseScalingOff()\n",
    "    procrustes_filter.SetConvergence(convergence)  # Minimum threshold to exit alignment\n",
    "    \n",
    "    # Set mesh correspondence inputs\n",
    "    procrustes_filter.SetNumberOfInputs(len(deformed_meshes))\n",
    "    for i in range(0, len(deformed_meshes)):\n",
    "        procrustes_filter.SetInput(i, deformed_meshes[i])\n",
    "    \n",
    "    # Run filter\n",
    "    procrustes_filter.Update()\n",
    "    \n",
    "    if(verbose):\n",
    "        print(f'Alignment converged at {procrustes_filter.GetMeanPointsDifference()}')\n",
    "    \n",
    "    mean_result = procrustes_filter.GetMean()\n",
    "    mean_result.SetCells(deformed_meshes[template_index].GetCells())\n",
    "    return mean_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Hausdorff Distance\n",
    "\n",
    "We can calculate the Hausdorff distance from the current to previous mesh atlas at each iterative refinement to quantify the amount of change between iterations. In this case the meshes are in correspondence so we get the largest Euclidean distance between any pair of correspondence points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hausdorff_distance(mesh1, mesh2):\n",
    "    assert(mesh1.GetNumberOfPoints() == mesh2.GetNumberOfPoints())\n",
    "    max_dist = 0.0\n",
    "    \n",
    "    for pt_idx in range(mesh1.GetNumberOfPoints()):\n",
    "        pt1 = mesh1.GetPoint(pt_idx)\n",
    "        pt2 = mesh2.GetPoint(pt_idx)\n",
    "        dist = sum((pt1[dim] - pt2[dim]) ** 2 for dim in range(0,3)) ** 0.5\n",
    "        max_dist = max(max_dist, dist)\n",
    "    return max_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Iterative Refinement\n",
    "\n",
    "Run registration and alignment on every mesh, choosing whether to iteratively update meshes to take advantage of mean alignment in each iteration or to ignore previous changes so that each alignment procedure is independent of the order of meshes in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the number of iterative refinements to run for each atlas.\n",
    "# One iteration includes registration to each dense mesh, followed by\n",
    "# subsequent Procrustes alignment of all correspondence meshes.\n",
    "NUM_ITERATIONS = 1\n",
    "\n",
    "# Select indices of atlas templates to refine.\n",
    "TEMPLATES_TO_ALIGN = [0]\n",
    "\n",
    "# Prepare directory to write out atlas iterations.\n",
    "# ex. 'Output/mean/0/901-L-femur-label.obj'\n",
    "for i in range(0,NUM_ITERATIONS):\n",
    "    os.makedirs(MEAN_OUTPUT_FOLDER + str(i) + '\\\\', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now at iteration 0\n",
      "Now at template mesh 0\n",
      "Resampling from mesh 0\n",
      "Resampling from mesh 1\n",
      "Resampling from mesh 2\n",
      "Resampling from mesh 3\n",
      "Resampling from mesh 4\n",
      "Resampling from mesh 5\n",
      "Resampling from mesh 6\n",
      "Resampling from mesh 7\n",
      "Resampling from mesh 8\n",
      "Resampling from mesh 9\n",
      "Resampling from mesh 10\n",
      "Resampling from mesh 11\n",
      "Resampling from mesh 12\n",
      "Resampling from mesh 13\n",
      "Running alignment\n",
      "Alignment converged at 0.0034345665327492492\n",
      "Writing mean to Output/mean//0/901-R-femur-label.obj\n",
      "Elapsed: 137.288982629776\n",
      "Mesh 0 Hausdorff distance from previous iteration: 2.228128978646963\n"
     ]
    }
   ],
   "source": [
    "aligned_templates = dict()\n",
    "for iteration in range(0,NUM_ITERATIONS):\n",
    "    print(f'Now at iteration {iteration}')\n",
    "    \n",
    "    for template_mesh_index in TEMPLATES_TO_ALIGN:\n",
    "        starttime = time.time()\n",
    "        print(f'Now at template mesh {template_mesh_index}')\n",
    "        template_mesh = sparse_meshes[template_mesh_index]\n",
    "\n",
    "        deformed_templates = list()\n",
    "        for sample_index in range(0,len(dense_meshes)):\n",
    "            print(f'Resampling from mesh {sample_index}')\n",
    "            deformed_template = register_template_to_sample(template_mesh, \n",
    "                                                            dense_meshes[sample_index],\n",
    "                                                            max_iterations=50)\n",
    "            deformed_templates.append(deformed_template)\n",
    "\n",
    "        print('Running alignment')\n",
    "        mesh_result = align_procrustes(deformed_templates, template_mesh_index, verbose=True)\n",
    "\n",
    "        # Save intermediate results to disk\n",
    "        # These meshes are very small so this is not a significant expense (~400 KB/mesh)\n",
    "        output_path = f'{MEAN_OUTPUT_FOLDER}/{iteration}/{MESH_FILENAMES[template_mesh_index]}'\n",
    "        print(f'Writing mean to {output_path}')\n",
    "        #itk.meshwrite(mesh_result, output_path)\n",
    "        \n",
    "        # Optionally update current mesh in place for use in subsequent alignments\n",
    "        aligned_templates[template_mesh_index] = mesh_result\n",
    "        \n",
    "        endtime = time.time()\n",
    "        print(f'Elapsed: {endtime - starttime}')\n",
    "    \n",
    "    # Optionally update templates only between iterations\n",
    "    for template_mesh_index in TEMPLATES_TO_ALIGN:\n",
    "        dist = calculate_hausdorff_distance(sparse_meshes[template_mesh_index],\n",
    "                                            aligned_templates[template_mesh_index])\n",
    "        print(f'Mesh {template_mesh_index} Hausdorff distance from previous iteration: {dist}')\n",
    "        sparse_meshes[template_mesh_index] = aligned_templates[template_mesh_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize template\n",
    "# view(geometries=sparse_meshes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
